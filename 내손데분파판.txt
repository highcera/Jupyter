df.to_csv('mycsv.csv', header=False,  index=False)
[주요 option]
mode='a'
encoding='utf-8' / 'cp949'
sep='\t' / '|'
skiprows=15

df = pd.read_csv('data.csv', sep=',', encoding='cp949', skiprows=15)

pd.read_csv('data1.csv', index_col=1)
1번째 column을 index로 사용

□ 내 손 데이터 분석 파이선 pandas 기초
데이터 프레임에서 series 추출하기
하나의 col. 만 선택하면 됨
countries = doc['Country_Region']

Series
size : 사이즈 반환, count() : 데이터 없는 경우를 뺀 사이즈 반환
unique() : 유일한 값만 반환, value_counts() : 데이터 없는 경우 제외, 각 값의 개수 반환

여러 컬럼 선택 시 별도의 dataframe이 됨
covid_stat = doc[['Confirmed', 'Deaths', 'Recovered']]

결측치 처리
  - isnull() : 없는 데이터가 있는지 확인 (True or False)
  - sum() : 없는 데이터가 있는 행의 갯수 확인 
  - 통상 isnull().sum() 으로 사용
  - dropna() : 결측치를 가진 행을 모두 삭제
    DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)

# 특정 컬럼값이 없는 데이터만 삭제하기
  - subset으로 해당 컬럼을 지정해줌
    doc = doc.dropna(subset=['Confirmed'])
# 없는 데이터(NaN)을 특정값으로 일괄 변경하기
- fillna(특정값) : 특정값으로 결측치를 대체
# 없는 데이터(NaN)중 특정 컬럼에 대해 특정 값으로 일괄 변경하기
- 별도 사전 데이터를 생성, 없는 데이터를 변경할 컬럼명만 키로 만들고, 변경할 특정 값을 키값으로 넣고, fillna() 함수에 적용해주면 됨
doc = pd.read_csv(PATH + "01-22-2020.csv", encoding='utf-8-sig')
nan_data = {'Deaths': 0, 'Recovered':0}
doc = doc.fillna(nan_data)
doc.head()
doc.colums 컬럼명 확인, 수정 가능

doc[doc.duplicated()]

5. 특정 키값을 기준으로 데이터 합치기
  - groupby() : SQL 구문의 group by 와 동일, 특정 컬럼을 기준으로 그룹
  - sum() : 그룹으로 되어 있는 데이터를 합치기
  - groupby 에 의해서, index가 특정 컬럼의 값으로 변경됨

6. 컬럼 타입 변경하기
  - pandas에서 데이터 타입은 dtype 으로 불리우며, 주요 데이터 타입은 다음과 같음
  - object 는 파이썬의 str 또는 혼용 데이터 타입 (문자열)
  - int64 는 파이썬의 int (정수)
  - float64 는 파이썬의 float (부동소숫점)
  - bool 는 파이썬의 bool (True 또는 False 값을 가지는 boolean)
    doc.info()

  - astype({컬럼명: 변경할타입}) : 특정 컬럼의 타입을 변경
  - 변경할 데이터에 없는 데이터(NaN)이 있을 경우, 에러가 날 수 있음

7. 데이터프레임 컬럼명 변경하기
  - columns 로 컬럼명을 변경할 수 있음

8. 데이터프레임에서 중복 행 확인/제거하기
  - duplicated() : 중복 행 확인하기
  
  - drop_ducplicates() : 중복 행 삭제중복값
  - 특정 컬럼을 기준으로 중복 행 제거하기
    - subset=특정컬럼
  - 중복된 경우, 처음과 마지막 행 중 어느 행을 남길 것인지 결정하기 
    - 처음: keep='first' (디폴트)
    - 마지막: keep='last'
    - 모두 제거 : keep='False'

■ 탐색적 데이터 분석 (EDA : Exploratory Data Analysis) 과정
https://github.com/CSSEGISandData/COVID-19

doc = pd.read_csv("파일명", encoding='utf-8-sig', quotechar=',')
doc = pd.read_csv("파일명", encoding='utf-8-sig', error_bad_lines=False)

pd.read_excel(파일명, sheet_name=시트명)

import pandas as pd
doc = pd.read_csv("COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports/04-01-2020.csv", encoding='utf-8-sig')

탐색적 데이터 분석: 1. 데이터의 출처와 주제에 대해 이해

탐색적 데이터 분석: 2. 데이터의 크기 확인
1. 데이터를 pandas로 읽은 후, 가장 먼저 하는 일
- 데이터 일부 확인하기
  - head(): 처음 5개(디폴트)의 데이터 확인하기
    - head(n=10): 처음 10개(조정 가능)의 데이터 확인하기 
  - tail(): 마지막 5개의 데이터 확인하기
    - tail(n=10): 마지막 10개(조정 가능)의 데이터 확인하기 

2. 보다 다양한 데이터 정보 확인하기
- shape: 데이터의 row, column 사이즈 확인
- info(): column별 데이터 타입과 실제 데이터가 있는 사이즈 확인
  - raw data는 일부 데이터가 없는 경우가 많기 때문에, 실제 데이터의 사이즈 확인이 필요함

탐색적 데이터 분석: 3. 데이터 구성 요소(feature)의 속성(특징) 확인
1. 각 column 이해하기
- raw data에는 다양한 column 이 있는 경우가 많고, 이 중에서 내가 사용할 column 에 대해서는 확실히 이해하고 있어야 함
- Country_Region: 국가, Lat/Long: 경도, Confirmed: 확진, Deaths: 사망, Recovered: 회복, Active: 확진 중인 사람(사망자/회복자 제외)
doc.columns

2. 속성이 숫자라면, 평균, 표준편차, 4분위 수, 최소/최대갑 확인하기
- describe(): 숫자 데이터의 기본 통계치를 한번에 확인할 수 있음
doc.describe()

3. 속성간 상관관계 이해하기
- corr(method=상관계수): 각 속성간 상관관계 확인하기 (피어슨 상관계수가 디폴트임)
- 피어슨 상관계수는 일반적으로 1에 가까우면 두 feature 간의 상관 관계가 높고, -1에 가까우면 관계가 없다고 해석됨
doc.corr()

주요 데이터 시각화 라이브러리
- matplotlib: 파이썬에서 가장 기본적으로 사용하는 자료를 그래프로 보여주는 시각화 라이브러리
  - 가장 좋기 때문에, 많이 사용된 것이 아니라, 이전부터 사용해왔기 때문에 사용된다고 하는 편이 맞음
- seaborn: matplotlib을 기반으로 다양한 통계 차트 및 색상 테마를 추가한 라이브러리
  - matplotlib 라이브러리로만은 이쁘지 않았고, 다양한 차트에 대한 요구가 많아서 개발된 라이브러리

# 화면에 표시될 그래프 사이즈 조정
sns.heatmap(data = doc.corr(), annot=True, fmt = '.2f', linewidths=0.5, cmap='Blues')

- data=테이블형: 데이터셋(데이터프레임)
- annot=True: 박스 안에 값 표시
- fmt='0.2f': 박스 안에 표시될 값의 표시 형식 설정 (0.2f 는 소숫점 두자릿수를 의미함)
- linewidths=0.5: 박스와 박스 사이의 간격 설정
- cmap='Blues': 색상 선택 (https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html)

%matplotlib inline 
import matplotlib.pyplot as plt 
import seaborn as sns

plt.figure(figsize=(5,5))

%matplotlib inline
import matplotlib.pyplot as plt 
import seaborn as sns

plt.figure(figsize=(5,5))
sns.heatmap(data = doc.corr(), annot=True, fmt = '.2f', linewidths=0.5, cmap='Blues')



동일 폴더 내 daily data 통합
1) dataframe 생성

import os
def generate_dateframe_by_path(PATH):

    file_list, csv_list = os.listdir(PATH), list()
    first_doc = True
    for file in file_list:
        if file.split(".")[-1] == 'csv':
            csv_list.append(file)
    csv_list.sort()
    
    for file in csv_list:
        doc = create_dateframe(file)
        if first_doc:
            final_doc, first_doc = doc, False
        else:
            final_doc = pd.merge(final_doc, doc, how='outer', left_index=True, right_index=True)

    final_doc = final_doc.fillna(0)
    return final_doc

import pandas as pd
import json, os 

with open('COVID-19-master/csse_covid_19_data/country_convert.json', 'r', encoding='utf-8-sig') as json_file:
    json_data = json.load(json_file)

def country_name_convert(row):
    if row['Country_Region'] in json_data:
        return json_data[row['Country_Region']]
    return row['Country_Region']

def create_dateframe(filename):
    doc = pd.read_csv(PATH + filename, encoding='utf-8-sig')  # 1. csv 파일 읽기
    try:
        doc = doc[['Country_Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기
    except:
        doc = doc[['Country/Region', 'Confirmed']]  # 2. 특정 컬럼만 선택해서 데이터프레임 만들기
        doc.columns = ['Country_Region', 'Confirmed']
    doc = doc.dropna(subset=['Confirmed'])     # 3. 특정 컬럼에 없는 데이터 삭제하기
    doc['Country_Region'] = doc.apply(country_name_convert, axis=1)   # 4. 'Country_Region'의 국가명을 여러 파일에 일관되게 변경하기
    doc = doc.astype({'Confirmed': 'int64'})   # 5. 특정 컬럼의 데이터 타입 변경하기
    doc = doc.groupby('Country_Region').sum()  # 6. 특정 컬럼으로 중복된 데이터를 합치기

    # 7. 파일명을 기반으로 날짜 문자열 변환하고, 'Confirmed' 컬럼명 변경하기
    date_column = filename.split(".")[0].lstrip('0').replace('-', '/') 
    doc.columns = [date_column]
    return doc